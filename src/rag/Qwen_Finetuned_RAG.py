# -*- coding: utf-8 -*-
"""FIPI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19xPOke6sdxYGED8jIEp0Z0DuzHwiP9_g
"""

import os
import json

# Save Kaggle token
kaggle_token = {"username":"ojaswayadav","key":"8bdb33a94914b05a7b59f1ab455c8db9"}

# Write kaggle.json
os.makedirs(os.path.expanduser("~/.kaggle"), exist_ok=True)
with open(os.path.expanduser("~/.kaggle/kaggle.json"), "w") as f:
    json.dump(kaggle_token, f)

# Set permissions for kaggle.json
os.chmod(os.path.expanduser("~/.kaggle/kaggle.json"), 0o600)

# Test Kaggle API access
!kaggle datasets list

import kaggle
import pandas as pd

# Download dataset using Kaggle API
kaggle.api.dataset_download_files('yousefsaeedian/financial-q-and-a-10k',
                                  path='./financial_qa', unzip=True)
print("Dataset downloaded and extracted successfully!")

# Load the dataset
financial_qa = pd.read_csv('/content/financial_qa/Financial-QA-10k.csv')
# Preview the dataset
print(financial_qa.head())

!pip install datasets transformers torch

!pip install chromadb

!pip install transformers==4.36.0 datasets sentencepiece
!pip install torch --index-url https://download.pytorch.org/whl/cu121
!pip install bitsandbytes>=0.41.1
!pip install accelerate
!pip install peft
!pip install sentence-transformers

from huggingface_hub import login

hf_token = "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"
login(token=hf_token)

from datasets import load_dataset

# Load Wealth Alpaca dataset
wealth_alpaca_dataset = load_dataset("gbharti/wealth-alpaca_lora")
wealth_alpaca_df = pd.DataFrame(wealth_alpaca_dataset["train"])

# Standardize columns
financial_qa = financial_qa.rename(columns={"question": "instruction", "answer": "output"})
financial_qa["input"] = ""  # Add empty 'input' column

# Combine both datasets
combined_dataset = pd.concat([financial_qa, wealth_alpaca_df], ignore_index=True)

# Save combined dataset if needed
combined_dataset.to_csv('combined_dataset.csv', index=False)

import pandas as pd
from datasets import load_dataset
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.config import Settings

# Step 4: Generate Embeddings using MiniLM
embedder = SentenceTransformer("all-MiniLM-L6-v2")
combined_dataset["combined_text"] = combined_dataset["instruction"] + " " + combined_dataset["input"]
corpus = combined_dataset["combined_text"].tolist()
embeddings = embedder.encode(corpus)

pip install chromadb --upgrade

# Clean the corpus by removing invalid entries (e.g., NaN or None)
corpus = [doc if isinstance(doc, str) else "" for doc in corpus]

# Verify there are no invalid documents
print(f"Total documents after cleaning: {len(corpus)}")

def store_in_chromadb(corpus, embeddings):
    """Store documents and embeddings in ChromaDB."""
    # Initialize ChromaDB client
    chroma_client = chromadb.PersistentClient(path="./chroma_db")

    # Create or get collection
    collection = chroma_client.get_or_create_collection(name="financial_wealth_corpus")

    # Convert embeddings to list if they're numpy array
    if hasattr(embeddings, 'tolist'):
        embeddings = embeddings.tolist()

    # Add documents in batches
    batch_size = 64
    total_docs = len(corpus)

    print(f"Starting to store {total_docs} documents...")

    try:
        for i in range(0, total_docs, batch_size):
            batch_end = min(i + batch_size, total_docs)
            batch_docs = corpus[i:batch_end]
            batch_embeddings = embeddings[i:batch_end]
            batch_ids = [str(j) for j in range(i, batch_end)]
            batch_metadata = [{"id": j} for j in range(i, batch_end)]

            print(f"Processing batch {i//batch_size + 1}: documents {i} to {batch_end}")

            # Verify data shapes before adding
            print(f"Batch size: {len(batch_docs)} documents, {len(batch_embeddings)} embeddings")

            collection.add(
                documents=batch_docs,
                embeddings=batch_embeddings,
                ids=batch_ids,
                metadatas=batch_metadata
            )

            print(f"Successfully added batch {i//batch_size + 1}")

        # Verify the collection has data
        collection_count = collection.count()
        print(f"Total documents in collection: {collection_count}")

        return collection

    except Exception as e:
        print(f"Error storing documents: {str(e)}")
        print(f"Document example: {corpus[0] if corpus else 'No documents'}")
        print(f"Embedding example shape: {len(embeddings[0]) if embeddings else 'No embeddings'}")
        raise

# Test the storage
def verify_chromadb_storage():
    print("\nVerifying ChromaDB storage:")
    client = chromadb.PersistentClient(path="./chroma_db")
    collections = client.list_collections()
    print(f"Number of collections: {len(collections)}")
    for collection in collections:
        print(f"Collection name: {collection.name}")
        print(f"Collection count: {collection.count()}")


store_in_chromadb(corpus, embeddings)
verify_chromadb_storage()

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from sentence_transformers import SentenceTransformer
import chromadb
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')

from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from nltk.translate.bleu_score import sentence_bleu
import numpy as np
import pandas as pd

import logging
import torch
import pandas as pd
from transformers import AutoTokenizer, AutoModelForCausalLM
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from nltk.translate.bleu_score import sentence_bleu
import chromadb
from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction
import numpy as np

logging.basicConfig(level=logging.INFO)


class FinancialRAG:
    def __init__(self, model_name="Ojaswa/my-trained-model"):
        logging.info("Initializing RAG system...")

        # Initialize model and tokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(
            model_name,
            trust_remote_code=True
        )
        self.model = AutoModelForCausalLM.from_pretrained(
            model_name,
            torch_dtype=torch.float16,
            device_map="auto",
            trust_remote_code=True
        )

        # Initialize ChromaDB
        self.chroma_client = chromadb.PersistentClient(path="./chroma_db")
        self.collection = self.chroma_client.get_collection("financial_wealth_corpus")

        # Initialize embedders
        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')
        self.embedder_eval = SentenceTransformer('all-MiniLM-L6-v2')

        logging.info(f"System initialized with {self.collection.count()} documents")

    def get_context(self, query, top_k=3):
        """Retrieve relevant context for the query"""
        try:
            query_embedding = self.embedder.encode(query, normalize_embeddings=True)
            results = self.collection.query(
                query_embeddings=[query_embedding.tolist()],
                n_results=top_k
            )
            return results["documents"][0]
        except Exception as e:
            logging.error(f"Error retrieving context: {e}")
            raise

    def generate_answer(self, query):
        """Generate answer using retrieved context"""
        try:
            context = self.get_context(query)
            context_text = " ".join(context)

            prompt = f"""<|im_start|>system
You are a financial advisor providing comprehensive and detailed analysis. Provide thorough explanations with examples where appropriate.
<|im_end|>
<|im_start|>user
{query}
<|im_end|>
<|im_start|>assistant
Here's a detailed analysis:"""

            inputs = self.tokenizer(
                prompt,
                return_tensors="pt",
                truncation=True,
                max_length=1024
            ).to(self.model.device)

            outputs = self.model.generate(
                **inputs,
                max_length=1024,    # Reduced for efficiency
                min_length=50,      # Reduced for efficiency
                temperature=0.7,
                top_p=0.9,
                num_return_sequences=1,
                no_repeat_ngram_size=3,
                early_stopping=True,
                pad_token_id=self.tokenizer.eos_token_id
            )

            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            if "<|im_start|>assistant" in response:
                response = response.split("<|im_start|>assistant")[-1].strip()

            return {"response": response}
        except Exception as e:
            logging.error(f"Error generating answer: {e}")
            raise

    def evaluate_performance(self, test_data):
        """Evaluate model performance using multiple metrics"""
        try:
            print("\nStarting Evaluation...")
            results = []
            references = test_data['answer'].tolist()

            for question in test_data['question']:
                rag_response = self.generate_answer(question)['response']
                results.append(rag_response)

            print("\n=== RAG Model Evaluation ===")
            rag_metrics = self._calculate_metrics(results, references)

            return {'rag': rag_metrics}
        except Exception as e:
            logging.error(f"Evaluation error: {e}")
            raise

    def _calculate_metrics(self, predictions, references):
        """Calculate evaluation metrics"""
        try:
            embedded_preds = self.embedder_eval.encode(predictions)
            embedded_refs = self.embedder_eval.encode(references)
            cosine_sims = [
                e for e in (cosine_similarity(embedded_preds, embedded_refs) * np.identity(len(predictions))).reshape(-1)
                if e != 0.0
            ]
            mean_cosine = np.mean(cosine_sims)

            bleu_scores = [sentence_bleu([ref.split()], pred.split()) for pred, ref in zip(predictions, references)]
            mean_bleu = np.mean(bleu_scores)

            print(f"Mean Cosine Similarity: {mean_cosine:.4f}")
            print(f"Mean BLEU Score: {mean_bleu:.4f}")

            return {
                'cosine_similarities': cosine_sims,
                'mean_cosine': mean_cosine,
                'bleu_scores': bleu_scores,
                'mean_bleu': mean_bleu
            }
        except Exception as e:
            logging.error(f"Metric calculation error: {e}")
            raise

    def run_interactive(self):
        """Run interactive Q&A session"""
        print("\nFinancial Advisory System")
        print("Type 'quit' to exit")
        print("-" * 50)

        while True:
            try:
                question = input("\nYour question: ").strip()
                if question.lower() == 'quit':
                    break

                print("\nAnalyzing...")
                result = self.generate_answer(question)

                print("\n=== Analysis ===")
                print(result["response"])
                print("\n" + "=" * 50)
            except Exception as e:
                print(f"\nError: {str(e)}")
                print("Please try another question.")


def main():
    try:
        rag = FinancialRAG()

        test_data = pd.DataFrame({
            'question': [
                "How do loans work?",
                "What is compound interest?",
                "Explain mortgage rates"
            ],
            'answer': [
                "A loan is borrowed money that must be repaid with interest over time...",
                "Compound interest is when interest is earned on both principal and accumulated interest...",
                "Mortgage rates are the interest rates charged on home loans..."
            ]
        })

        print("Running evaluation...")
        evaluation_results = rag.evaluate_performance(test_data)

        print("\nStarting interactive session...")
        rag.run_interactive()
    except Exception as e:
        logging.error(f"System error: {e}")
        raise


if __name__ == "__main__":
    main()





